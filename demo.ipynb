{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attributions for Siamese Encoders - Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from xsbert import utils\n",
    "from xsbert.models import XSMPNet, XSRoberta, load_model\n",
    "import zipfile\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import wget\n",
    "from os import PathLike\n",
    "import zipfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loading a model\n",
    "\n",
    "You can either load one of the two models that we provide with the `load_model()` method as follows.\n",
    "Downloading the checkpoint the first time will take a while. It is then stored in the directory specified by `model_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'xs_mpnet'\n",
    "model = load_model(model_name, model_dir='../xs_models/')\n",
    "model.to(torch.device('cuda:1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already downloaded a checkpoint or want to load one that you created yourself, you can alternatively load it direcly using the respective model classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'checkpoints/xs_mpnet/'\n",
    "# model = XSMPNet(model_path)\n",
    "# model_path = 'checkpoints/xs_distilroberta/'\n",
    "# model = XSRoberta(model_path)\n",
    "# model.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initializing attributions\n",
    "\n",
    "The `init_attribution_to_layer()` method of the `models.XSTransformer` class initializes attributions to the layer with index `idx`. `N_steps` is the number of approximation steps to calculate the *integrated Jacobians* ($N$ in the paper).\n",
    "\n",
    "`reset_attribution()` removes all hooks that are registered on the model for calculating attributions. After calling it, you can initialize attributions to a different layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_attribution()\n",
    "model.init_attribution_to_layer(idx=8, N_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### computing attributions\n",
    "\n",
    "In this demo we compute the attribution matrix for a single pair of texts that you can define here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texta = 'This is not a good coffee.'\n",
    "textb = 'The coffee is bad.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing attributions (above), we use the method `attribute_prediction` in the `models.XSTransformer` class to compute the attribution matrix $A$.\n",
    "\n",
    "When setting the argument `compute_lhs` the method explicitly computes the four terms in the ansatz (left-hand-side of Equation 2 in the paper), $f(a, b) - f(r, a) - f(r, b) + f(r, r)$. Below they are name as `score`, `ra`, `rb`, and `rr` in the respective order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, tokens_a, tokens_b, score, ra, rb, rr = model.attribute_prediction(\n",
    "    texta, \n",
    "    textb, \n",
    "    move_to_cpu=False,\n",
    "    compute_lhs=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attribution accuracy\n",
    "\n",
    "The first term, $f(a, b)$ (`score`), is the actual model prediction.\n",
    "Due to the embedding shift implemented in the `models.ShiftingReferenceTransformer` (cf. Section 2.2 in the paper), by construction, the three terms including a reference $r$ must vanish. Below, we explicitly check that this is the case.\n",
    "\n",
    "We can also calculate how accurate our attributions are by taking the absolute difference between their sum and the model (as described in Section 3.2 of the paper): $\\text{error} = \\|\\sum_{ij} A_{ij} - f(a, b)\\|$.\n",
    "\n",
    "You can change the number of approximation steps $N$ in the `init_attribution_to_layer()` method to see how this attribution error changes.\n",
    "Generally, attributions to shallower layers require larger $N$ (cf. Section 3.2 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_attr = A.sum().item()\n",
    "attr_err = torch.abs(A.sum() - score).item()\n",
    "print('model prediction: ', score)\n",
    "print('total attribution: ', tot_attr)\n",
    "print('reference terms: ', ra, rb, rr)\n",
    "print('attribution error: ', attr_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting attributions\n",
    "\n",
    "Finally, we can plot the token-token attribution matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_attributions(\n",
    "    A, \n",
    "    tokens_a, \n",
    "    tokens_b, \n",
    "    size=(2, 2),\n",
    "    range=.1,\n",
    "    show_colobar=True, \n",
    "    shrink_cbar=.5\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
